---
title: "Introduction to the rda file"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{rdaFile}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, message = FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message=FALSE, 
                      warning=FALSE, 
                      fig.height=5, 
                      fig.width=8,
                      collapse = TRUE,
                      comment = "#>")

```

```{r setup}
library(nphys)

```

When we want to quickly access any of the data associated with any individual data point or experiment, we load the rda file asssociated with that experiment and apply functions to elements of the nested list.

Loading the rda file imports a nested list to the environment containing all of the information and variables we need to quickly and reliably analyze our data.

We also want to be able to able to nteract with the data and effeciently incorporate updated analysis into our ongoing project.

Having easy access to our data is one of the primary reasons we are doing this work.

We are going to utilize the `field` dataset to look at examples of how we can work with the comprehensive rda file that we've built over the course of our experiment and examine how we can take advantage of this methodology.

# What is in the file

Running an experiment with the help of R enables us to ensure that consistency is maintained across all avenues of the experimental procedure. Running neurophysiology experiments requires constant remaning focused on the responses being generated, while also retaining relevant information for later analysis. 
Running the function `newField()` will enable us to add a new field experiment to our dataset, by prompting us through a number of important questions that will fill in the metadata component to our dataset. It will also generate folders and paths for us to place our experimental data so that the raw data can easily imported  

After we have run our experiment, compiled our metadata, imported our raw data, and loaded our rda file into the REnvironment, we end up with a nested list (in this case `field`) that represents our experiment. 

The nested list is made up of a number of useful components. It contains the working directory of our rda file relative to the project directory (`field$wd`), all of the identifying metadata needed for analyzing our data and adding it to our project (`field$md`), the path to the files we imported (`field$files`), and the imported data itself. Since we imported files of the ABF format, we keep `field$ABF` as the principle call format for accessing the data. 

### The metadata contains identifying information unique to the experiment we've run
You can decide what information you deem important for your md by updating the params file. 

```{r}
knitr::kable(field$md[1:9], row.names = FALSE)
knitr::kable(field$md[10:15], row.names = FALSE)
```

The `field$files` component is a list of the raw data files collected during our experiment, which are also relative to the project directory.

```{r}
print(field$files)
```

Finally, the `field$ABF` component of our nested list contains all of the raw data imported during our experimental protocol, including any metadata that is kept by the software. We will go over importing data in another document, but for the time being it is imporant to note that interaction with the console will be required to ensure that your data is properly labeled, and therefore be identifiable. 

```{r}
names(field$ABF)
names(field$ABF[[1]])
```

# Using functions over the rda data. 

`i.e. function(field$ABF)`.

## The dfs_ABF() function

We can extract the data or other useful information nested in the `field$ABF` compnent of our list, by calling the `dfs_ABF` function on our imported data.

The default selection is the `"data"` component of the ABF file, which will return a list of dataframes that make up the sweeps from what we imported.

```{r}
dfs <- dfs_ABF(field$ABF)
# Names of imported data
print(head(names(dfs)))

# Individual traces are named by their sweep when defaut selections are run
print(names(dfs[1]))
```

### Other data stored in the ABF file. 

This function can also be used to extract other important information about the imported data. Accessing this information is very useful when you need to identify the names of your channels, sampling fequency, or other things. 

```{r}
head(dfs_ABF(field$ABF, int = "samplingIntervalInSec"),3)
```

**The select option** is helpful when you're uncertain what you're looking for.  
There are numerous parameters kept by the pClamp software that can be very used for ordering and managing your datasets (See the ABF file format vignette for more information). Using the select option will enable you to select from a list of elements that make up the identifying and metadata components for each imported file.


```{r eval = FALSE}
# Select from list by selecting from options
dfs_ABF(field$ABF, select = TRUE)

# Provide numeric input to identify the numer representing the list element. 
dfs_ABF(field$ABF, select = 4)
```

It can be useful to simplify the output by specifying `returnList = FALSE`, which will unlist the data, potentialy making it easier to work with later. The default is `TRUE`, and this option should only be used when returning something with a small footprint like sampling interval. Using this on `data` will result in end up with a flurry of numbers that you can't keep up with. 


```{r}
dfs_ABF(field$ABF, int = "samplingIntervalInSec", returnList = FALSE)
```


## The pullSweeps function

Pulling sweeps goes one step further than `dfs_ABF`, and enables you to conviently select a range of sweeps from your data. Again, we feed the dataset into a function (`pullSweeps(field$ABF)`), and the function returns a dataframe of sweeps from the protocol we are interested in. 

## specific sweeps or sets of sweeps from the $ABF

```{r}
Sweeps <- pullSweeps(field$ABF)
head(names(Sweeps))
tail(names(Sweeps))
```

We can identify which protocol we want our sweeps pulled from by using the `pull =` argument. Default is set to `pull = PreC-Bl`, which is the "pre-conditioning baseline". There is also the option to select from a list of the protocol identifiers, to easily develop analysis of other components to the experiment.   

To select from a list of protocol names:
```{r, eval = FALSE}
Sweeps = pullSweeps(field$ABF, select = TRUE)
```

To select based upon numeric input:

```{r, eval = FALSE}
Sweeps = pullSweeps(field$ABF, select = 1)
names(Sweeps)
head(Sweeps)
```


### Adjusting the sweeps to zero
This function has a built in option to adjust the baseline as well, which calls the `nphys` function `zeroAdjust`. The default is to zero the baseline, but we can return the dataframe without adjusting the baseline by setting the option to zero to false. 

```{r}
Sweeps = pullSweeps(field$ABF, select = 1, zero = FALSE)
head(Sweeps)
```


```{r}

x = dfs_ABF(field$ABF)[[1]][[1]]
round(head(x),digits = 3)

x = zeroAdjust(x)
round(head(x),digits = 3)


```

Options for this function can be modified to change the baseline range over which the sweep will be adjusted against.

```{r}
x = dfs_ABF(field$ABF)[[1]][[1]]
round(head(x),digits = 3)
x = zeroAdjust(x, r = 1200:1500)
round(head(x),digits = 3)

```


